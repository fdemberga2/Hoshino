{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arcega\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from prophet import Prophet\n",
    "import holidays\n",
    "from prophet.diagnostics import cross_validation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weekend(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    # Return True for Saturday (5) and Sunday (6), False otherwise\n",
    "    return date.weekday() >= 5\n",
    "\n",
    "def df_to_X_y(df, window_size=6):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - window_size):\n",
    "        row = [r for r in df_as_np[i:i + window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i + window_size][6]  # 'Entry' is the 7th column (index 6)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def mean_absolute_scaled_error(test, y_true, y_pred):\n",
    "    seasonality = 20\n",
    "\n",
    "    seasonal_naive = test.copy()\n",
    "    seasonal_naive['yhat'] = test['y'].shift(20)\n",
    "    seasonal_naive['yhat'].fillna(test['y'][:20].mean(), inplace=True)\n",
    "\n",
    "    naive_errors = np.abs(seasonal_naive['y'] - seasonal_naive['yhat'])\n",
    "\n",
    "    # Mean absolute error of the naive forecast\n",
    "    naive_mae = np.mean(naive_errors)\n",
    "    naive_mae\n",
    "\n",
    "    # Ensure inputs are numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate the absolute error of the model's predictions\n",
    "    abs_error = np.mean(np.abs(y_true - y_pred))\n",
    "    \n",
    "    # MASE calculation\n",
    "    mase = abs_error / naive_mae\n",
    "\n",
    "    return mase\n",
    "\n",
    "def evaluate_model(test, test_forecast):\n",
    "    # Evaluate performance\n",
    "    mse = mean_squared_error(y_true=test['y'],  y_pred=test_forecast['yhat'])\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=test['y'], y_pred=test_forecast['yhat']))\n",
    "    mae = mean_absolute_error(y_true=test['y'], y_pred=test_forecast['yhat'])\n",
    "    r2 = r2_score(y_true=test['y'], y_pred=test_forecast['yhat'])\n",
    "    mase = mean_absolute_scaled_error(test, y_true=test['y'],  y_pred=test_forecast['yhat'])\n",
    "    return mse, rmse, mae, r2, mase\n",
    "\n",
    "\n",
    "def prophet_model(train, test, df):\n",
    "    # Create holidays dataframe\n",
    "    holiday = pd.DataFrame([])\n",
    "    for date, name in sorted(holidays.Philippines(years=[2022, 2023]).items()):\n",
    "        holiday = pd.concat([holiday, pd.DataFrame({'ds': date, 'holiday': name}, index=[0])], ignore_index=True)\n",
    "    holiday['ds'] = pd.to_datetime(holiday['ds'], format='%Y-%m-%d', errors='ignore')\n",
    "\n",
    "    # Initialize the Prophet model\n",
    "    m = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=True,\n",
    "        holidays=holiday,\n",
    "        seasonality_mode='multiplicative'\n",
    "    )\n",
    "\n",
    "    # Add the regressors\n",
    "    m.add_seasonality(name='daily_is_weekend', period=1, fourier_order=4, condition_name='weekend')\n",
    "    m.add_seasonality(name='daily_is_weekday', period=1, fourier_order=4, condition_name='weekday')\n",
    "    m.add_regressor('off_hour')\n",
    "    m.add_regressor('rain_amount')\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    m.fit(train)\n",
    "\n",
    "    # Make predictions for Test set\n",
    "    test_forecast = m.predict(test)\n",
    "\n",
    "    # Remove negative forecasts\n",
    "    test_forecast['yhat'] = test_forecast['yhat'].apply(lambda x: max(x, 0))\n",
    "    test_forecast['yhat_lower'] = test_forecast['yhat_lower'].apply(lambda x: max(x, 0))\n",
    "    test_forecast['yhat_upper'] = test_forecast['yhat_upper'].apply(lambda x: max(x, 0))\n",
    "    test_forecast['yhat'] = test_forecast['yhat'].round()\n",
    "\n",
    "    # Round forecast values\n",
    "    test_forecast['yhat'] = test_forecast['yhat'].round()\n",
    "\n",
    "    # Create a future DataFrame with hourly intervals for the desired forecast period\n",
    "    future = m.make_future_dataframe(periods=150, freq='D')\n",
    "    future['hour'] = pd.to_datetime(future['ds']).dt.hour\n",
    "    future['is_weekend'] = df['is_weekend']\n",
    "    future['weekday'] = future['ds'].apply(is_weekend)\n",
    "    future['weekend'] = ~future['ds'].apply(is_weekend)\n",
    "    future['rain_amount'] = df['rain_amount']\n",
    "    future['off_hour'] = future['hour'].apply(lambda x: 1 if (x >= 23) or (x <= 3) else 0)\n",
    "    future = future[future['ds'].dt.hour < 23]\n",
    "    future = future[future['ds'].dt.hour > 3]\n",
    "\n",
    "    # Make predictions for future set\n",
    "    forecast = m.predict(future)\n",
    "    \n",
    "    return test_forecast\n",
    "\n",
    "def lstm_model(df, X_train, y_train, X_test, y_test, X_val, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer((X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='linear'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Define the ModelCheckpoint callback with the correct file path\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    cp1 = ModelCheckpoint(filepath='model/best_lstm.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    # Use early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=[cp1, early_stopping])\n",
    "\n",
    "    # Assuming df is the original DataFrame with the 'Date Time' column\n",
    "    # Extract the 'Date Time' column for the entire dataset\n",
    "    date_time_test = df['Date Time']\n",
    "\n",
    "    # Load the scaler for inverse transformation\n",
    "    scaler_entry = joblib.load('model/scaler_entry.pkl')\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform the predictions and actual values\n",
    "    # Create a DataFrame to hold the predictions and actual values\n",
    "    df_pred = pd.DataFrame(y_pred, columns=['Entry'])\n",
    "    df_actual = pd.DataFrame(y_test, columns=['Entry'])\n",
    "\n",
    "    # Inverse transform the 'Entry' column\n",
    "    y_pred_inv = scaler_entry.inverse_transform(df_pred)\n",
    "    y_test_inv = scaler_entry.inverse_transform(df_actual)\n",
    "\n",
    "    # Ensure date_time_test matches the length of y_test_inv and y_pred_inv\n",
    "    date_time_test = date_time_test[-len(y_test_inv):]\n",
    "\n",
    "    # Round the predictions to the nearest whole number and ensure non-negative values\n",
    "    y_pred_inv = np.round(np.maximum(y_pred_inv, 0))\n",
    "    y_test_inv = np.round(np.maximum(y_test_inv, 0))\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    l_mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "    l_rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "    l_mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    l_r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "    return y_pred_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:42:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "07:43:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390194.7712328767, 624.6557221645189, 424.26027397260276, 0.8020142777903155, 1.007264783095724, array([   0, 2941, 4881, ..., 1807,   64,    0], dtype=int64), array([   0,  365,  503, ..., 1807,   64,    0], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('data/00_MRT_2023_Prophet_weather2.csv', parse_dates=[0])\n",
    "\n",
    "# Rename header to Prophet's requirements\n",
    "df.reset_index()\n",
    "df = df.rename(columns={'Datetime':'ds', 'Entry':'y'})\n",
    "\n",
    "# Add additional regressors as columns in the dataframe\n",
    "df['hour'] = pd.to_datetime(df['ds']).dt.hour\n",
    "df['off_hour'] = df['hour'].apply(lambda x: 1 if (x >= 23) or (x <= 3) else 0)\n",
    "df['weekday'] = ~df['ds'].apply(is_weekend)\n",
    "df['weekend'] = df['ds'].apply(is_weekend)\n",
    "\n",
    "# Split the dataset to training and testing sets\n",
    "train_len = math.floor((df.shape[0]*80)/100)\n",
    "train = df[:train_len]\n",
    "test = df[train_len:]\n",
    "\n",
    "test_forecast = prophet_model(train, test, df)\n",
    "prophet_eval = evaluate_model(test, test_forecast)\n",
    "print(prophet_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arcega\\AppData\\Local\\Temp\\ipykernel_17232\\3982592567.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Arcega\\AppData\\Local\\Temp\\ipykernel_17232\\3982592567.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 6, 64)             18432     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 64)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,569\n",
      "Trainable params: 53,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "365/365 [==============================] - 9s 12ms/step - loss: 0.0221 - val_loss: 0.0122\n",
      "Epoch 2/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 3/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 4/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 5/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 7/100\n",
      "365/365 [==============================] - 3s 10ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 8/100\n",
      "365/365 [==============================] - 3s 10ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 9/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 10/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 11/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 12/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 13/100\n",
      "365/365 [==============================] - 3s 10ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 14/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 15/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 16/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 17/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 18/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 19/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 20/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 23/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 24/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 25/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 26/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 27/100\n",
      "365/365 [==============================] - 3s 10ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 28/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "365/365 [==============================] - 3s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 31/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 32/100\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 33/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 34/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 35/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 36/100\n",
      "365/365 [==============================] - 5s 15ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 37/100\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 38/100\n",
      "365/365 [==============================] - 6s 16ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "365/365 [==============================] - 7s 19ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "365/365 [==============================] - 6s 15ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 43/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 44/100\n",
      "365/365 [==============================] - 5s 12ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 45/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 46/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 47/100\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 48/100\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "46/46 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load your time series data\n",
    "df2 = pd.read_csv('data/2223TaftLSTM.csv')\n",
    "\n",
    "# Set if holiday\n",
    "ph_holidays = holidays.PH()\n",
    "df2['is_holiday'] = df2['Date'].apply(lambda x: 1 if x in ph_holidays else 0)\n",
    "df2.head(5)\n",
    "\n",
    "# Combine 'Date' and 'Time' into a new column 'DateAndTime'\n",
    "df2['DateAndTime'] = pd.to_datetime(df2['Date'] + ' ' + df2['Time'])\n",
    "\n",
    "# Drop unneeded columns\n",
    "df2.drop(['Date', 'Time', 'rain_amount', 'rain_desc'], axis=1, inplace=True)\n",
    "\n",
    " # Define additional features\n",
    "df2['Date Time'] = pd.to_datetime(df2['DateAndTime'], format='%d.%m.%Y %H.%M.%S')\n",
    "df2['hour'] = df2['Date Time'].dt.hour\n",
    "df2['day_of_week'] = df2['Date Time'].dt.dayofweek\n",
    "df2['month'] = df2['Date Time'].dt.month\n",
    "df2['year'] = df2['Date Time'].dt.year\n",
    "df2.drop(['DateAndTime', 'Day', 'is_weekend'], axis=1, inplace=True)\n",
    "df2['is_weekend'] = df2['day_of_week'].apply(lambda x: 1 if x in [5, 6] else 0)\n",
    "model_features = ['hour', 'day_of_week', 'is_weekend', 'month', 'year', 'rain_class', 'Entry']\n",
    "df_model = df2[model_features]\n",
    "\n",
    "# Normalize all features except 'Entry'\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_model[df_model.columns[:-1]] = scaler.fit_transform(df_model[df_model.columns[:-1]])\n",
    "\n",
    "# Save the scaler for the features\n",
    "joblib.dump(scaler, 'model/scaler_features.pkl')\n",
    "\n",
    "# Normalize the 'Entry' column separately\n",
    "scaler_entry = MinMaxScaler(feature_range=(0, 1))\n",
    "df_model['Entry'] = scaler_entry.fit_transform(df_model[['Entry']])\n",
    "\n",
    "# Save the scaler for the 'Entry' column\n",
    "joblib.dump(scaler_entry, 'model/scaler_entry.pkl')\n",
    "\n",
    "#\n",
    "X, y = df_to_X_y(df_model)\n",
    "\n",
    "# Determine the split points\n",
    "train_split_point = int(len(X) * 0.8)\n",
    "valntest_split_point = int(len(X) * 0.9)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, X_test = X[:train_split_point], X[train_split_point:valntest_split_point], X[valntest_split_point:]\n",
    "y_train, y_val, y_test = y[:train_split_point], y[train_split_point:valntest_split_point], y[valntest_split_point:]\n",
    "\n",
    "lstm_forecast = lstm_model(df2, X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4493.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        yhat\n",
       "0       68.0\n",
       "1     2454.0\n",
       "2     4646.0\n",
       "3     5510.0\n",
       "4     4493.0\n",
       "...      ...\n",
       "1455  1759.0\n",
       "1456  1286.0\n",
       "1457   114.0\n",
       "1458    94.0\n",
       "1459    25.0\n",
       "\n",
       "[1460 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_forecast = pd.DataFrame(lstm_forecast, columns=['yhat'])\n",
    "lstm_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>All Saints' Day</th>\n",
       "      <th>All Saints' Day_lower</th>\n",
       "      <th>All Saints' Day_upper</th>\n",
       "      <th>Black Saturday</th>\n",
       "      <th>...</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-08 04:00:00</td>\n",
       "      <td>1502.743646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>510.126623</td>\n",
       "      <td>1502.743646</td>\n",
       "      <td>1502.743646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083363</td>\n",
       "      <td>0.083363</td>\n",
       "      <td>0.083363</td>\n",
       "      <td>-0.038610</td>\n",
       "      <td>-0.038610</td>\n",
       "      <td>-0.038610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-08 05:00:00</td>\n",
       "      <td>1502.802962</td>\n",
       "      <td>2163.813607</td>\n",
       "      <td>3351.338957</td>\n",
       "      <td>1502.802962</td>\n",
       "      <td>1502.802962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079941</td>\n",
       "      <td>0.079941</td>\n",
       "      <td>0.079941</td>\n",
       "      <td>-0.038131</td>\n",
       "      <td>-0.038131</td>\n",
       "      <td>-0.038131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-08 06:00:00</td>\n",
       "      <td>1502.862279</td>\n",
       "      <td>3826.584526</td>\n",
       "      <td>4991.548456</td>\n",
       "      <td>1502.862279</td>\n",
       "      <td>1502.862279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076329</td>\n",
       "      <td>0.076329</td>\n",
       "      <td>0.076329</td>\n",
       "      <td>-0.037649</td>\n",
       "      <td>-0.037649</td>\n",
       "      <td>-0.037649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-08 07:00:00</td>\n",
       "      <td>1502.921595</td>\n",
       "      <td>4245.614791</td>\n",
       "      <td>5403.567113</td>\n",
       "      <td>1502.921595</td>\n",
       "      <td>1502.921595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>-0.037165</td>\n",
       "      <td>-0.037165</td>\n",
       "      <td>-0.037165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-08 08:00:00</td>\n",
       "      <td>1502.980911</td>\n",
       "      <td>3684.792798</td>\n",
       "      <td>4879.281279</td>\n",
       "      <td>1502.980911</td>\n",
       "      <td>1502.980911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068760</td>\n",
       "      <td>0.068760</td>\n",
       "      <td>0.068760</td>\n",
       "      <td>-0.036677</td>\n",
       "      <td>-0.036677</td>\n",
       "      <td>-0.036677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>1710.054302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5706.200706</td>\n",
       "      <td>-599.262201</td>\n",
       "      <td>4157.714562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080293</td>\n",
       "      <td>-0.080293</td>\n",
       "      <td>-0.080293</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>1710.113618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4308.824659</td>\n",
       "      <td>-600.532736</td>\n",
       "      <td>4159.993532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071339</td>\n",
       "      <td>-0.071339</td>\n",
       "      <td>-0.071339</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>1710.172935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1843.995869</td>\n",
       "      <td>-601.803271</td>\n",
       "      <td>4162.272503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>1710.232251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>518.313797</td>\n",
       "      <td>-603.073806</td>\n",
       "      <td>4164.551473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052290</td>\n",
       "      <td>-0.052290</td>\n",
       "      <td>-0.052290</td>\n",
       "      <td>-0.008801</td>\n",
       "      <td>-0.008801</td>\n",
       "      <td>-0.008801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>1710.291567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>484.112053</td>\n",
       "      <td>-604.344341</td>\n",
       "      <td>4166.830444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>-0.008326</td>\n",
       "      <td>-0.008326</td>\n",
       "      <td>-0.008326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2920 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ds        trend   yhat_lower   yhat_upper  trend_lower  \\\n",
       "0    2023-08-08 04:00:00  1502.743646     0.000000   510.126623  1502.743646   \n",
       "1    2023-08-08 05:00:00  1502.802962  2163.813607  3351.338957  1502.802962   \n",
       "2    2023-08-08 06:00:00  1502.862279  3826.584526  4991.548456  1502.862279   \n",
       "3    2023-08-08 07:00:00  1502.921595  4245.614791  5403.567113  1502.921595   \n",
       "4    2023-08-08 08:00:00  1502.980911  3684.792798  4879.281279  1502.980911   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "2915 2023-12-31 19:00:00  1710.054302     0.000000  5706.200706  -599.262201   \n",
       "2916 2023-12-31 20:00:00  1710.113618     0.000000  4308.824659  -600.532736   \n",
       "2917 2023-12-31 21:00:00  1710.172935     0.000000  1843.995869  -601.803271   \n",
       "2918 2023-12-31 22:00:00  1710.232251     0.000000   518.313797  -603.073806   \n",
       "2919 2023-12-31 23:00:00  1710.291567     0.000000   484.112053  -604.344341   \n",
       "\n",
       "      trend_upper  All Saints' Day  All Saints' Day_lower  \\\n",
       "0     1502.743646              0.0                    0.0   \n",
       "1     1502.802962              0.0                    0.0   \n",
       "2     1502.862279              0.0                    0.0   \n",
       "3     1502.921595              0.0                    0.0   \n",
       "4     1502.980911              0.0                    0.0   \n",
       "...           ...              ...                    ...   \n",
       "2915  4157.714562              0.0                    0.0   \n",
       "2916  4159.993532              0.0                    0.0   \n",
       "2917  4162.272503              0.0                    0.0   \n",
       "2918  4164.551473              0.0                    0.0   \n",
       "2919  4166.830444              0.0                    0.0   \n",
       "\n",
       "      All Saints' Day_upper  Black Saturday  ...    weekly  weekly_lower  \\\n",
       "0                       0.0             0.0  ...  0.083363      0.083363   \n",
       "1                       0.0             0.0  ...  0.079941      0.079941   \n",
       "2                       0.0             0.0  ...  0.076329      0.076329   \n",
       "3                       0.0             0.0  ...  0.072584      0.072584   \n",
       "4                       0.0             0.0  ...  0.068760      0.068760   \n",
       "...                     ...             ...  ...       ...           ...   \n",
       "2915                    0.0             0.0  ... -0.080293     -0.080293   \n",
       "2916                    0.0             0.0  ... -0.071339     -0.071339   \n",
       "2917                    0.0             0.0  ... -0.061977     -0.061977   \n",
       "2918                    0.0             0.0  ... -0.052290     -0.052290   \n",
       "2919                    0.0             0.0  ... -0.042360     -0.042360   \n",
       "\n",
       "      weekly_upper    yearly  yearly_lower  yearly_upper  additive_terms  \\\n",
       "0         0.083363 -0.038610     -0.038610     -0.038610             0.0   \n",
       "1         0.079941 -0.038131     -0.038131     -0.038131             0.0   \n",
       "2         0.076329 -0.037649     -0.037649     -0.037649             0.0   \n",
       "3         0.072584 -0.037165     -0.037165     -0.037165             0.0   \n",
       "4         0.068760 -0.036677     -0.036677     -0.036677             0.0   \n",
       "...            ...       ...           ...           ...             ...   \n",
       "2915     -0.080293 -0.010234     -0.010234     -0.010234             0.0   \n",
       "2916     -0.071339 -0.009755     -0.009755     -0.009755             0.0   \n",
       "2917     -0.061977 -0.009277     -0.009277     -0.009277             0.0   \n",
       "2918     -0.052290 -0.008801     -0.008801     -0.008801             0.0   \n",
       "2919     -0.042360 -0.008326     -0.008326     -0.008326             0.0   \n",
       "\n",
       "      additive_terms_lower  additive_terms_upper    yhat  \n",
       "0                      0.0                   0.0     0.0  \n",
       "1                      0.0                   0.0  2736.0  \n",
       "2                      0.0                   0.0  4448.0  \n",
       "3                      0.0                   0.0  4818.0  \n",
       "4                      0.0                   0.0  4298.0  \n",
       "...                    ...                   ...     ...  \n",
       "2915                   0.0                   0.0  2322.0  \n",
       "2916                   0.0                   0.0  1778.0  \n",
       "2917                   0.0                   0.0   688.0  \n",
       "2918                   0.0                   0.0     0.0  \n",
       "2919                   0.0                   0.0     0.0  \n",
       "\n",
       "[2920 rows x 94 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ds        trend   yhat_lower   yhat_upper  trend_lower  \\\n",
      "0    2023-10-20 04:00:00  1606.665897     0.000000   249.058671   843.347072   \n",
      "1    2023-10-20 05:00:00  1606.725214  1265.650428  4107.043782   842.408332   \n",
      "2    2023-10-20 06:00:00  1606.784530  2261.082918  6881.410177   840.501558   \n",
      "3    2023-10-20 07:00:00  1606.843846  2603.707275  7516.132866   839.096894   \n",
      "4    2023-10-20 08:00:00  1606.903163  2206.426627  6776.709256   837.715808   \n",
      "...                  ...          ...          ...          ...          ...   \n",
      "1455 2023-12-31 19:00:00  1710.054302     0.000000  5706.200706  -599.262201   \n",
      "1456 2023-12-31 20:00:00  1710.113618     0.000000  4308.824659  -600.532736   \n",
      "1457 2023-12-31 21:00:00  1710.172935     0.000000  1843.995869  -601.803271   \n",
      "1458 2023-12-31 22:00:00  1710.232251     0.000000   518.313797  -603.073806   \n",
      "1459 2023-12-31 23:00:00  1710.291567     0.000000   484.112053  -604.344341   \n",
      "\n",
      "      trend_upper  All Saints' Day  All Saints' Day_lower  \\\n",
      "0     2381.277436              0.0                    0.0   \n",
      "1     2382.092229              0.0                    0.0   \n",
      "2     2382.907022              0.0                    0.0   \n",
      "3     2383.721815              0.0                    0.0   \n",
      "4     2384.536608              0.0                    0.0   \n",
      "...           ...              ...                    ...   \n",
      "1455  4157.714562              0.0                    0.0   \n",
      "1456  4159.993532              0.0                    0.0   \n",
      "1457  4162.272503              0.0                    0.0   \n",
      "1458  4164.551473              0.0                    0.0   \n",
      "1459  4166.830444              0.0                    0.0   \n",
      "\n",
      "      All Saints' Day_upper  Black Saturday  ...    weekly  weekly_lower  \\\n",
      "0                       0.0             0.0  ... -0.026443     -0.026443   \n",
      "1                       0.0             0.0  ... -0.021457     -0.021457   \n",
      "2                       0.0             0.0  ... -0.016175     -0.016175   \n",
      "3                       0.0             0.0  ... -0.010652     -0.010652   \n",
      "4                       0.0             0.0  ... -0.004951     -0.004951   \n",
      "...                     ...             ...  ...       ...           ...   \n",
      "1455                    0.0             0.0  ... -0.080293     -0.080293   \n",
      "1456                    0.0             0.0  ... -0.071339     -0.071339   \n",
      "1457                    0.0             0.0  ... -0.061977     -0.061977   \n",
      "1458                    0.0             0.0  ... -0.052290     -0.052290   \n",
      "1459                    0.0             0.0  ... -0.042360     -0.042360   \n",
      "\n",
      "      weekly_upper    yearly  yearly_lower  yearly_upper  additive_terms  \\\n",
      "0        -0.026443 -0.064640     -0.064640     -0.064640             0.0   \n",
      "1        -0.021457 -0.065450     -0.065450     -0.065450             0.0   \n",
      "2        -0.016175 -0.066255     -0.066255     -0.066255             0.0   \n",
      "3        -0.010652 -0.067057     -0.067057     -0.067057             0.0   \n",
      "4        -0.004951 -0.067854     -0.067854     -0.067854             0.0   \n",
      "...            ...       ...           ...           ...             ...   \n",
      "1455     -0.080293 -0.010234     -0.010234     -0.010234             0.0   \n",
      "1456     -0.071339 -0.009755     -0.009755     -0.009755             0.0   \n",
      "1457     -0.061977 -0.009277     -0.009277     -0.009277             0.0   \n",
      "1458     -0.052290 -0.008801     -0.008801     -0.008801             0.0   \n",
      "1459     -0.042360 -0.008326     -0.008326     -0.008326             0.0   \n",
      "\n",
      "      additive_terms_lower  additive_terms_upper    yhat  \n",
      "0                      0.0                   0.0     0.0  \n",
      "1                      0.0                   0.0  2664.0  \n",
      "2                      0.0                   0.0  4507.0  \n",
      "3                      0.0                   0.0  4916.0  \n",
      "4                      0.0                   0.0  4372.0  \n",
      "...                    ...                   ...     ...  \n",
      "1455                   0.0                   0.0  2322.0  \n",
      "1456                   0.0                   0.0  1778.0  \n",
      "1457                   0.0                   0.0   688.0  \n",
      "1458                   0.0                   0.0     0.0  \n",
      "1459                   0.0                   0.0     0.0  \n",
      "\n",
      "[1460 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows\n",
    "num_rows = len(test_forecast)\n",
    "\n",
    "# Calculate the midpoint\n",
    "midpoint = num_rows // 2\n",
    "\n",
    "# Take the latter half\n",
    "prophet_forecast = test_forecast[midpoint:]\n",
    "test_one = test[:midpoint]\n",
    "hybrid_actual = test[midpoint:]\n",
    "\n",
    "# Reset the index of the DataFrame and drop the old index\n",
    "prophet_forecast.reset_index(drop=True, inplace=True)\n",
    "hybrid_actual.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(prophet_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ds  prophet    lstm     y\n",
      "0    2023-10-20 04:00:00      0.0    68.0     0\n",
      "1    2023-10-20 05:00:00   2664.0  2454.0  2894\n",
      "2    2023-10-20 06:00:00   4507.0  4646.0  4339\n",
      "3    2023-10-20 07:00:00   4916.0  5510.0  5548\n",
      "4    2023-10-20 08:00:00   4372.0  4493.0  4502\n",
      "...                  ...      ...     ...   ...\n",
      "1455 2023-12-31 19:00:00   2322.0  1759.0  1681\n",
      "1456 2023-12-31 20:00:00   1778.0  1286.0   297\n",
      "1457 2023-12-31 21:00:00    688.0   114.0     0\n",
      "1458 2023-12-31 22:00:00      0.0    94.0     0\n",
      "1459 2023-12-31 23:00:00      0.0    25.0     0\n",
      "\n",
      "[1460 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "hybrid_forecast = prophet_forecast[['ds', 'yhat']].rename(columns={'yhat': 'prophet'})\n",
    "hybrid_forecast['lstm'] = lstm_forecast['yhat']\n",
    "hybrid_forecast['y'] = hybrid_actual['y']\n",
    "print(hybrid_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Evaluate prophet\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mse, rmse, mae, r2, mase \u001b[38;5;241m=\u001b[39m evaluate_model(hybrid_forecast,prophet_forecast)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "#Evaluate prophet\n",
    "mse, rmse, mae, r2, mase = evaluate_model(hybrid_forecast,prophet_forecast)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"MASE: {mase:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 99913.6158\n",
      "RMSE: 316.0912\n",
      "MAE: 198.0774\n",
      "R²: 0.9456\n",
      "MASE: 0.4741\n"
     ]
    }
   ],
   "source": [
    "#Evaluate lstm\n",
    "mse, rmse, mae, r2, mase = evaluate_model(hybrid_forecast,lstm_forecast)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"MASE: {mase:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 103292.7215\n",
      "RMSE: 321.3919\n",
      "MAE: 202.8217\n",
      "R²: 0.9437\n",
      "MASE: 0.4855\n"
     ]
    }
   ],
   "source": [
    "# Define weights\n",
    "weight_prophet =0.1\n",
    "weight_lstm = 0.9\n",
    "# Calculate the hybrid forecast\n",
    "hybrid_forecast['yhat'] = (\n",
    "    weight_prophet * hybrid_forecast['prophet'] + \n",
    "    weight_lstm * hybrid_forecast['lstm']\n",
    ")\n",
    "\n",
    "actual = hybrid_forecast['y']\n",
    "forecast = hybrid_forecast['yhat']\n",
    "\n",
    "#Evaluate hybrid forecast\n",
    "mse, rmse, mae, r2, mase = evaluate_model(hybrid_forecast, hybrid_forecast)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"MASE: {mase:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arcega\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from prophet import Prophet\n",
    "import holidays\n",
    "from prophet.diagnostics import cross_validation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weekend(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    # Return True for Saturday (5) and Sunday (6), False otherwise\n",
    "    return date.weekday() >= 5\n",
    "\n",
    "def df_to_X_y(df, window_size=6):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - window_size):\n",
    "        row = [r for r in df_as_np[i:i + window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i + window_size][6]  # 'Entry' is the 7th column (index 6)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def mean_absolute_scaled_error(test, y_true, y_pred):\n",
    "    seasonality = 20\n",
    "\n",
    "    seasonal_naive = test.copy()\n",
    "    seasonal_naive['yhat'] = test['y'].shift(20)\n",
    "    seasonal_naive['yhat'].fillna(test['y'][:20].mean(), inplace=True)\n",
    "\n",
    "    naive_errors = np.abs(seasonal_naive['y'] - seasonal_naive['yhat'])\n",
    "\n",
    "    # Mean absolute error of the naive forecast\n",
    "    naive_mae = np.mean(naive_errors)\n",
    "    naive_mae\n",
    "\n",
    "    # Ensure inputs are numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate the absolute error of the model's predictions\n",
    "    abs_error = np.mean(np.abs(y_true - y_pred))\n",
    "    \n",
    "    # MASE calculation\n",
    "    mase = abs_error / naive_mae\n",
    "\n",
    "    return mase\n",
    "\n",
    "def evaluate_model(test, test_forecast):\n",
    "    # Evaluate performance\n",
    "    mse = mean_squared_error(y_true=test['y'],  y_pred=test_forecast['yhat'])\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=test['y'], y_pred=test_forecast['yhat']))\n",
    "    mae = mean_absolute_error(y_true=test['y'], y_pred=test_forecast['yhat'])\n",
    "    r2 = r2_score(y_true=test['y'], y_pred=test_forecast['yhat'])\n",
    "    mase = mean_absolute_scaled_error(test, y_true=test['y'],  y_pred=test_forecast['yhat'])\n",
    "    return mse, rmse, mae, r2, mase\n",
    "\n",
    "\n",
    "def prophet_model(train, test, df):\n",
    "    # Create holidays dataframe\n",
    "    holiday = pd.DataFrame([])\n",
    "    for date, name in sorted(holidays.Philippines(years=[2022, 2023]).items()):\n",
    "        holiday = pd.concat([holiday, pd.DataFrame({'ds': date, 'holiday': name}, index=[0])], ignore_index=True)\n",
    "    holiday['ds'] = pd.to_datetime(holiday['ds'], format='%Y-%m-%d', errors='ignore')\n",
    "    holiday.loc[holiday['ds'] == '2023-11-30', 'ds'] = '2023-11-27'\n",
    "\n",
    "    # Initialize the Prophet model\n",
    "    m = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=True,\n",
    "        holidays=holiday,\n",
    "        seasonality_mode='multiplicative',\n",
    "        seasonality_prior_scale=0.1,\n",
    "        changepoint_prior_scale=0.001,\n",
    "\n",
    "    )\n",
    "\n",
    "    # Add custom seasonality\n",
    "    m.add_seasonality(name='daily_is_weekend', period=1, fourier_order=4, condition_name='weekend')\n",
    "    m.add_seasonality(name='daily_is_weekday', period=1, fourier_order=4, condition_name='weekday')\n",
    "\n",
    "    # Add additional regressor\n",
    "    m.add_regressor('off_hour')\n",
    "    m.add_regressor('rain_amount')\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    m.fit(train)\n",
    "\n",
    "    # Make predictions for Test set\n",
    "    test_forecast = m.predict(test)\n",
    "\n",
    "    # Remove negative forecasts\n",
    "    test_forecast['yhat'] = test_forecast['yhat'].apply(lambda x: max(x, 0))\n",
    "    test_forecast['yhat_lower'] = test_forecast['yhat_lower'].apply(lambda x: max(x, 0))\n",
    "    test_forecast['yhat_upper'] = test_forecast['yhat_upper'].apply(lambda x: max(x, 0))\n",
    "    test_forecast['yhat'] = test_forecast['yhat'].round()\n",
    "\n",
    "    # Round forecast values\n",
    "    test_forecast['yhat'] = test_forecast['yhat'].round()\n",
    "\n",
    "    # Create a future DataFrame with hourly intervals for the desired forecast period\n",
    "    future = m.make_future_dataframe(periods=150, freq='D')\n",
    "    future['hour'] = pd.to_datetime(future['ds']).dt.hour\n",
    "    future['is_weekend'] = df['is_weekend']\n",
    "    future['weekday'] = future['ds'].apply(is_weekend)\n",
    "    future['weekend'] = ~future['ds'].apply(is_weekend)\n",
    "    future['rain_amount'] = df['rain_amount']\n",
    "    future['off_hour'] = future['hour'].apply(lambda x: 1 if (x >= 23) or (x <= 3) else 0)\n",
    "    future = future[future['ds'].dt.hour < 23]\n",
    "    future = future[future['ds'].dt.hour > 3]\n",
    "\n",
    "    # make predictions\n",
    "    forecast = m.predict(future)\n",
    "    \n",
    "    return test_forecast\n",
    "\n",
    "def lstm_model(df, X_train, y_train, X_test, y_test, X_val, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer((X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='linear'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Define the ModelCheckpoint callback with the correct file path\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    cp1 = ModelCheckpoint(filepath='model/best_lstm.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    # Use early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=[cp1, early_stopping])\n",
    "\n",
    "    # Assuming df is the original DataFrame with the 'Date Time' column\n",
    "    # Extract the 'Date Time' column for the entire dataset\n",
    "    date_time_test = df['Date Time']\n",
    "\n",
    "    # Load the scaler for inverse transformation\n",
    "    scaler_entry = joblib.load('model/scaler_entry.pkl')\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform the predictions and actual values\n",
    "    # Create a DataFrame to hold the predictions and actual values\n",
    "    df_pred = pd.DataFrame(y_pred, columns=['Entry'])\n",
    "    df_actual = pd.DataFrame(y_test, columns=['Entry'])\n",
    "\n",
    "    # Inverse transform the 'Entry' column\n",
    "    y_pred_inv = scaler_entry.inverse_transform(df_pred)\n",
    "    y_test_inv = scaler_entry.inverse_transform(df_actual)\n",
    "\n",
    "    # Ensure date_time_test matches the length of y_test_inv and y_pred_inv\n",
    "    date_time_test = date_time_test[-len(y_test_inv):]\n",
    "\n",
    "    # Round the predictions to the nearest whole number and ensure non-negative values\n",
    "    y_pred_inv = np.round(np.maximum(y_pred_inv, 0))\n",
    "    y_test_inv = np.round(np.maximum(y_test_inv, 0))\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    l_mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "    l_rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "    l_mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    l_r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "    return y_pred_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:05:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:06:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446872.9226027397, 668.4855440491887, 516.9554794520548, 0.7565910827339437, 1.2373866501497068)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arcega\\AppData\\Local\\Temp\\ipykernel_6040\\3957576142.py:22: FutureWarning:\n",
      "\n",
      "The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('data/2223TaftProphet.csv', parse_dates=[0])\n",
    "\n",
    "# Rename header to Prophet's requirements\n",
    "df.reset_index()\n",
    "df = df.rename(columns={'Datetime':'ds', 'Entry':'y'})\n",
    "\n",
    "# Add additional regressors as columns in the dataframe\n",
    "df['hour'] = pd.to_datetime(df['ds']).dt.hour\n",
    "df['off_hour'] = df['hour'].apply(lambda x: 1 if (x >= 23) or (x <= 3) else 0)\n",
    "df['weekday'] = ~df['ds'].apply(is_weekend)\n",
    "df['weekend'] = df['ds'].apply(is_weekend)\n",
    "\n",
    "# Split the dataset to training and testing sets\n",
    "train_len = math.floor((df.shape[0]*80)/100)\n",
    "train = df[:train_len]\n",
    "test = df[train_len:]\n",
    "test_len = math.floor((test.shape[0]*50)/100)\n",
    "val = test[:test_len]\n",
    "test = test[test_len:]\n",
    "\n",
    "test_forecast = prophet_model(train, test, df)\n",
    "prophet_eval = evaluate_model(test, test_forecast)\n",
    "print(prophet_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arcega\\AppData\\Local\\Temp\\ipykernel_6040\\3982592567.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Arcega\\AppData\\Local\\Temp\\ipykernel_6040\\3982592567.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 6, 64)             18432     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 64)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,569\n",
      "Trainable params: 53,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "365/365 [==============================] - 66s 67ms/step - loss: 0.0215 - val_loss: 0.0096\n",
      "Epoch 2/100\n",
      "365/365 [==============================] - 14s 38ms/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 3/100\n",
      "365/365 [==============================] - 11s 29ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 4/100\n",
      "365/365 [==============================] - 9s 25ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 5/100\n",
      "365/365 [==============================] - 7s 18ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "365/365 [==============================] - 6s 17ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 7/100\n",
      "365/365 [==============================] - 5s 15ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 8/100\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 9/100\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 10/100\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 11/100\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 12/100\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 13/100\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "365/365 [==============================] - 8s 22ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 15/100\n",
      "365/365 [==============================] - 12s 34ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 16/100\n",
      "365/365 [==============================] - 12s 32ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 17/100\n",
      "365/365 [==============================] - 13s 35ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 18/100\n",
      "365/365 [==============================] - 12s 33ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 19/100\n",
      "365/365 [==============================] - 12s 33ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 20/100\n",
      "365/365 [==============================] - 12s 32ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 21/100\n",
      "365/365 [==============================] - 12s 34ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 22/100\n",
      "365/365 [==============================] - 14s 38ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 23/100\n",
      "365/365 [==============================] - 13s 35ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 24/100\n",
      "365/365 [==============================] - 12s 34ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 25/100\n",
      "365/365 [==============================] - 12s 34ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 26/100\n",
      "365/365 [==============================] - 13s 37ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 27/100\n",
      "365/365 [==============================] - 13s 35ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 28/100\n",
      "365/365 [==============================] - 14s 37ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "365/365 [==============================] - 12s 32ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "365/365 [==============================] - 13s 36ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "365/365 [==============================] - 13s 35ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 32/100\n",
      "365/365 [==============================] - 14s 39ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 33/100\n",
      "365/365 [==============================] - 16s 45ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 34/100\n",
      "365/365 [==============================] - 13s 36ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "365/365 [==============================] - 14s 37ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 36/100\n",
      "365/365 [==============================] - 13s 35ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "365/365 [==============================] - 16s 45ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "365/365 [==============================] - 20s 56ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "365/365 [==============================] - 18s 48ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 40/100\n",
      "365/365 [==============================] - 12s 34ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 41/100\n",
      "365/365 [==============================] - 14s 38ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "365/365 [==============================] - 12s 34ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 43/100\n",
      "365/365 [==============================] - 11s 29ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "365/365 [==============================] - 9s 26ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 45/100\n",
      "365/365 [==============================] - 8s 21ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "365/365 [==============================] - 6s 16ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "365/365 [==============================] - 6s 18ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "365/365 [==============================] - 6s 16ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 49/100\n",
      "365/365 [==============================] - 6s 16ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "365/365 [==============================] - 6s 17ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "365/365 [==============================] - 6s 16ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 52/100\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 53/100\n",
      "365/365 [==============================] - 6s 15ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "46/46 [==============================] - 19s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load your time series data\n",
    "df2 = pd.read_csv('data/2223TaftLSTM.csv')\n",
    "\n",
    "# Set if holiday\n",
    "ph_holidays = holidays.PH()\n",
    "df2['is_holiday'] = df2['Date'].apply(lambda x: 1 if x in ph_holidays else 0)\n",
    "df2.head(5)\n",
    "\n",
    "# Combine 'Date' and 'Time' into a new column 'DateAndTime'\n",
    "df2['DateAndTime'] = pd.to_datetime(df2['Date'] + ' ' + df2['Time'])\n",
    "\n",
    "# Drop unneeded columns\n",
    "df2.drop(['Date', 'Time', 'rain_amount', 'rain_desc'], axis=1, inplace=True)\n",
    "\n",
    " # Define additional features\n",
    "df2['Date Time'] = pd.to_datetime(df2['DateAndTime'], format='%d.%m.%Y %H.%M.%S')\n",
    "df2['hour'] = df2['Date Time'].dt.hour\n",
    "df2['day_of_week'] = df2['Date Time'].dt.dayofweek\n",
    "df2['month'] = df2['Date Time'].dt.month\n",
    "df2['year'] = df2['Date Time'].dt.year\n",
    "df2.drop(['DateAndTime', 'Day', 'is_weekend'], axis=1, inplace=True)\n",
    "df2['is_weekend'] = df2['day_of_week'].apply(lambda x: 1 if x in [5, 6] else 0)\n",
    "model_features = ['hour', 'day_of_week', 'is_weekend', 'month', 'year', 'rain_class', 'Entry']\n",
    "df_model = df2[model_features]\n",
    "\n",
    "# Normalize all features except 'Entry'\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_model[df_model.columns[:-1]] = scaler.fit_transform(df_model[df_model.columns[:-1]])\n",
    "\n",
    "# Save the scaler for the features\n",
    "joblib.dump(scaler, 'model/scaler_features.pkl')\n",
    "\n",
    "# Normalize the 'Entry' column separately\n",
    "scaler_entry = MinMaxScaler(feature_range=(0, 1))\n",
    "df_model['Entry'] = scaler_entry.fit_transform(df_model[['Entry']])\n",
    "\n",
    "# Save the scaler for the 'Entry' column\n",
    "joblib.dump(scaler_entry, 'model/scaler_entry.pkl')\n",
    "\n",
    "#\n",
    "X, y = df_to_X_y(df_model)\n",
    "\n",
    "# Determine the split points\n",
    "train_split_point = int(len(X) * 0.8)\n",
    "valntest_split_point = int(len(X) * 0.9)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, X_test = X[:train_split_point], X[train_split_point:valntest_split_point], X[valntest_split_point:]\n",
    "y_train, y_val, y_test = y[:train_split_point], y[train_split_point:valntest_split_point], y[valntest_split_point:]\n",
    "\n",
    "lstm_forecast = lstm_model(df2, X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        yhat\n",
       "0        3.0\n",
       "1     2583.0\n",
       "2     4857.0\n",
       "3     5612.0\n",
       "4     4354.0\n",
       "...      ...\n",
       "1455  1880.0\n",
       "1456  1283.0\n",
       "1457    37.0\n",
       "1458    29.0\n",
       "1459     0.0\n",
       "\n",
       "[1460 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_forecast = pd.DataFrame(lstm_forecast, columns=['yhat'])\n",
    "lstm_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_forecast = test_forecast.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ds  prophet    lstm     y\n",
      "0    2023-10-20 04:00:00      0.0     3.0     0\n",
      "1    2023-10-20 05:00:00   2043.0  2583.0  2894\n",
      "2    2023-10-20 06:00:00   3624.0  4857.0  4339\n",
      "3    2023-10-20 07:00:00   4063.0  5612.0  5548\n",
      "4    2023-10-20 08:00:00   3637.0  4354.0  4502\n",
      "...                  ...      ...     ...   ...\n",
      "1455 2023-12-31 19:00:00   2346.0  1880.0  1681\n",
      "1456 2023-12-31 20:00:00   1828.0  1283.0   297\n",
      "1457 2023-12-31 21:00:00    923.0    37.0     0\n",
      "1458 2023-12-31 22:00:00      0.0    29.0     0\n",
      "1459 2023-12-31 23:00:00      0.0     0.0     0\n",
      "\n",
      "[1460 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# combine prophet and lstm forecast into one dataframe\n",
    "test_actual = test\n",
    "\n",
    "hybrid_forecast = prophet_forecast[['ds', 'yhat']].rename(columns={'yhat': 'prophet'})\n",
    "hybrid_forecast['lstm'] = lstm_forecast['yhat']\n",
    "hybrid_forecast['y'] = test_actual['y']\n",
    "print(hybrid_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 446872.9226\n",
      "RMSE: 668.4855\n",
      "MAE: 516.9555\n",
      "R²: 0.7566\n",
      "MASE: 1.2374\n"
     ]
    }
   ],
   "source": [
    "#Evaluate prophet\n",
    "mse, rmse, mae, r2, mase = evaluate_model(hybrid_forecast,prophet_forecast)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"MASE: {mase:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 117929.3199\n",
      "RMSE: 343.4084\n",
      "MAE: 215.4418\n",
      "R²: 0.9358\n",
      "MASE: 0.5157\n"
     ]
    }
   ],
   "source": [
    "#Evaluate lstm\n",
    "mse, rmse, mae, r2, mase = evaluate_model(hybrid_forecast,lstm_forecast)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"MASE: {mase:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 120398.4172\n",
      "RMSE: 346.9848\n",
      "MAE: 222.7252\n",
      "R²: 0.9344\n",
      "MASE: 0.5331\n"
     ]
    }
   ],
   "source": [
    "# Define weights\n",
    "weight_prophet =0.1\n",
    "weight_lstm = 0.9\n",
    "# Calculate the hybrid forecast\n",
    "hybrid_forecast['yhat'] = (\n",
    "    weight_prophet * hybrid_forecast['prophet'] + \n",
    "    weight_lstm * hybrid_forecast['lstm']\n",
    ")\n",
    "\n",
    "actual = hybrid_forecast['y']\n",
    "forecast = hybrid_forecast['yhat']\n",
    "\n",
    "#Evaluate hybrid forecast\n",
    "mse, rmse, mae, r2, mase = evaluate_model(hybrid_forecast, hybrid_forecast)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"MASE: {mase:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_weights(hybrid_forecast, actuals_col, prophet_col, lstm_col, metric, step):\n",
    "    best_metric = float('inf')\n",
    "    best_weights = (0, 0)\n",
    "\n",
    "    # Iterate through Prophet weights from 0 to 1, LSTM weights are (1 - prophet_weight)\n",
    "    for w_prophet in np.arange(0, 1 + step, step):\n",
    "        w_lstm = 1 - w_prophet\n",
    "        \n",
    "        # Calculate weighted forecast\n",
    "        hybrid_forecast['hybrid'] = (w_prophet * hybrid_forecast[prophet_col]) + (w_lstm * hybrid_forecast[lstm_col])\n",
    "        \n",
    "        # Evaluate the hybrid forecast\n",
    "        if metric == 'rmse':\n",
    "            metric_value = np.sqrt(mean_squared_error(hybrid_forecast[actuals_col], hybrid_forecast['hybrid']))\n",
    "        elif metric == 'mae':\n",
    "            metric_value = np.mean(np.abs(hybrid_forecast[actuals_col] - hybrid_forecast['hybrid']))\n",
    "        elif metric == 'mase':\n",
    "            naive_forecast = hybrid_forecast[actuals_col].shift(20).dropna()\n",
    "            naive_errors = np.abs(hybrid_forecast[actuals_col].iloc[20:] - naive_forecast)\n",
    "            metric_value = np.mean(np.abs(hybrid_forecast[actuals_col].iloc[20:] - hybrid_forecast['hybrid'].iloc[20:])) / np.mean(naive_errors)\n",
    "\n",
    "        # Store the best weights and metric\n",
    "        if metric_value < best_metric:\n",
    "            best_metric = metric_value\n",
    "            best_weights = (w_prophet, w_lstm)\n",
    "        print(metric_value)\n",
    "\n",
    "    return best_weights, best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343.4083864191638\n",
      "346.9847506103604\n",
      "360.03980608855517\n",
      "381.60204176081953\n",
      "410.3324047054664\n",
      "444.8443367112923\n",
      "483.90227953721586\n",
      "526.4955111943276\n",
      "571.8346136217859\n",
      "619.3167912791854\n",
      "668.4855440491887\n",
      "Best Weights - Prophet: 0.0, LSTM: 1.0\n",
      "Best RMSE: 343.4083864191638\n"
     ]
    }
   ],
   "source": [
    "best_weights, best_metric = find_best_weights(\n",
    "    hybrid_forecast=hybrid_forecast, \n",
    "    actuals_col='y', \n",
    "    prophet_col='prophet', \n",
    "    lstm_col='lstm', \n",
    "    metric='rmse', \n",
    "    step=0.1\n",
    ")\n",
    "\n",
    "print(f\"Best Weights - Prophet: {best_weights[0]}, LSTM: {best_weights[1]}\")\n",
    "print(f\"Best RMSE: {best_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from prophet import Prophet\n",
    "import holidays\n",
    "from prophet.diagnostics import cross_validation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weekend(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    # Return True for Saturday (5) and Sunday (6), False otherwise\n",
    "    return date.weekday() >= 5\n",
    "\n",
    "def df_to_X_y(df, window_size=6):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - window_size):\n",
    "        row = [r for r in df_as_np[i:i + window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i + window_size][6]  # 'Entry' is the 7th column (index 6)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def evaluate_model(test, test_forecast):\n",
    "    # Evaluate performance\n",
    "    mse = mean_squared_error(y_true=test['y'],  y_pred=test_forecast['yhat'])\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=test['y'], y_pred=test_forecast['yhat']))\n",
    "    mae = mean_absolute_error(y_true=test['y'], y_pred=test_forecast['yhat'])\n",
    "    r2 = r2_score(y_true=test['y'], y_pred=test_forecast['yhat'])\n",
    "    return mse, rmse, mae, r2\n",
    "\n",
    "def evaluatel(y_test_inv, y_pred_inv):\n",
    "        # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "    mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "    return mse, rmse, mae, r2\n",
    "\n",
    "def prophet_model(train, test, df):\n",
    "    # Set evaluation metrics to 0\n",
    "    p_rmse = 0\n",
    "    p_mse = 0\n",
    "    p_mae = 0\n",
    "    p_r2 = 0\n",
    "\n",
    "\n",
    "    # Create holidays dataframe\n",
    "    holiday = pd.DataFrame([])\n",
    "    for date, name in sorted(holidays.Philippines(years=[2022, 2023]).items()):\n",
    "        holiday = pd.concat([holiday, pd.DataFrame({'ds': date, 'holiday': name}, index=[0])], ignore_index=True)\n",
    "    holiday['ds'] = pd.to_datetime(holiday['ds'], format='%Y-%m-%d', errors='ignore')\n",
    "\n",
    "    # Initialize the Prophet model\n",
    "    m = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=True,\n",
    "        holidays=holiday,\n",
    "        seasonality_mode='multiplicative',\n",
    "        scaling='minmax'\n",
    "    )\n",
    "\n",
    "    # Add the regressors\n",
    "    m.add_seasonality(name='daily_is_weekend', period=1, fourier_order=4, condition_name='weekend')\n",
    "    m.add_seasonality(name='daily_is_weekday', period=1, fourier_order=4, condition_name='weekday')\n",
    "    m.add_regressor('off_hour')\n",
    "    m.add_regressor('rain_amount')\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    m.fit(train)\n",
    "\n",
    "    # Make predictions for Test set\n",
    "    test_forecast = m.predict(test)\n",
    "\n",
    "    # Remove negative forecasts\n",
    "    test_forecast['yhat'] = test_forecast['yhat'].apply(lambda x: max(x, 0))\n",
    "    test_forecast['yhat_lower'] = test_forecast['yhat_lower'].apply(lambda x: max(x, 0))\n",
    "    test_forecast['yhat_upper'] = test_forecast['yhat_upper'].apply(lambda x: max(x, 0))\n",
    "\n",
    "    # Round forecast values\n",
    "    test_forecast['yhat'] = test_forecast['yhat'].round()\n",
    "\n",
    "    # Create a future DataFrame with hourly intervals for the desired forecast period\n",
    "    future = m.make_future_dataframe(periods=150, freq='D')\n",
    "    future['hour'] = pd.to_datetime(future['ds']).dt.hour\n",
    "    future['is_weekend'] = df['is_weekend']\n",
    "    future['weekday'] = future['ds'].apply(is_weekend)\n",
    "    future['weekend'] = ~future['ds'].apply(is_weekend)\n",
    "    future['rain_amount'] = df['rain_amount']\n",
    "    future['off_hour'] = future['hour'].apply(lambda x: 1 if (x >= 23) or (x <= 3) else 0)\n",
    "    future = future[future['ds'].dt.hour < 23]\n",
    "    future = future[future['ds'].dt.hour > 3]\n",
    "\n",
    "    # Make predictions for future set\n",
    "    forecast = m.predict(future)\n",
    "    \n",
    "    return test_forecast\n",
    "\n",
    "def lstm_model(df, X_train, y_train, X_test, y_test, X_val, y_val):\n",
    "    \"\"\"model = Sequential()\n",
    "    model.add(InputLayer((6, 5)))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(8, 'relu'))\n",
    "    model.add(Dense(1, 'linear'))\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer((X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Define the ModelCheckpoint callback with the correct file path\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    cp1 = ModelCheckpoint(filepath='model/best_lstm.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    # Use early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, callbacks=[cp1, early_stopping])\n",
    "\n",
    "    # Assuming df is the original DataFrame with the 'Date Time' column\n",
    "    # Extract the 'Date Time' column for the entire dataset\n",
    "    date_time_test = df['Date Time']\n",
    "\n",
    "    # Load the scaler for inverse transformation\n",
    "    scaler_entry = joblib.load('model/scaler_entry.pkl')\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform the predictions and actual values\n",
    "    # Create a DataFrame to hold the predictions and actual values\n",
    "    df_pred = pd.DataFrame(y_pred, columns=['Entry'])\n",
    "    df_actual = pd.DataFrame(y_test, columns=['Entry'])\n",
    "\n",
    "    # Inverse transform the 'Entry' column\n",
    "    y_pred_inv = scaler_entry.inverse_transform(df_pred)\n",
    "    y_test_inv = scaler_entry.inverse_transform(df_actual)\n",
    "\n",
    "    # Ensure date_time_test matches the length of y_test_inv and y_pred_inv\n",
    "    date_time_test = date_time_test[-len(y_test_inv):]\n",
    "\n",
    "    # Round the predictions to the nearest whole number and ensure non-negative values\n",
    "    y_pred_inv = np.round(np.maximum(y_pred_inv, 0))\n",
    "    y_test_inv = np.round(np.maximum(y_test_inv, 0))\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    l_mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "    l_rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "    l_mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    l_r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "    return y_pred_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:29:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:29:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390194.7712328767, 624.6557221645189, 424.26027397260276, 0.8020142777903155)\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('data/00_MRT_2023_Prophet_weather2.csv', parse_dates=[0])\n",
    "\n",
    "# Rename header to Prophet's requirements\n",
    "df.reset_index()\n",
    "df = df.rename(columns={'Datetime':'ds', 'Entry':'y'})\n",
    "\n",
    "# Add additional regressors as columns in the dataframe\n",
    "df['hour'] = pd.to_datetime(df['ds']).dt.hour\n",
    "df['off_hour'] = df['hour'].apply(lambda x: 1 if (x >= 23) or (x <= 3) else 0)\n",
    "df['weekday'] = ~df['ds'].apply(is_weekend)\n",
    "df['weekend'] = df['ds'].apply(is_weekend)\n",
    "\n",
    "# Split the dataset to training and testing sets\n",
    "train_len = math.floor((df.shape[0]*80)/100)\n",
    "train = df[:train_len]\n",
    "test = df[train_len:]\n",
    "\n",
    "test_forecast = prophet_model(train, test, df)\n",
    "prophet_eval = evaluate_model(test, test_forecast)\n",
    "print(prophet_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arcega\\AppData\\Local\\Temp\\ipykernel_14836\\2921249495.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Arcega\\AppData\\Local\\Temp\\ipykernel_14836\\2921249495.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 6, 64)             18432     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 6, 64)             0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,569\n",
      "Trainable params: 53,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "365/365 [==============================] - 8s 11ms/step - loss: 0.0225 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 3/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 4/50\n",
      "365/365 [==============================] - 3s 8ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 9/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 13/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 14/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 15/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 18/50\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "365/365 [==============================] - 3s 8ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 22/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 23/50\n",
      "365/365 [==============================] - 3s 8ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 24/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 26/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "365/365 [==============================] - 3s 8ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 36/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 40/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 41/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 43/50\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "46/46 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load your time series data\n",
    "df2 = pd.read_csv('data/2223TaftLSTM.csv')\n",
    "\n",
    "# Set if holiday\n",
    "ph_holidays = holidays.PH()\n",
    "df2['is_holiday'] = df2['Date'].apply(lambda x: 1 if x in ph_holidays else 0)\n",
    "df2.head(5)\n",
    "\n",
    "# Combine 'Date' and 'Time' into a new column 'DateAndTime'\n",
    "df2['DateAndTime'] = pd.to_datetime(df2['Date'] + ' ' + df2['Time'])\n",
    "\n",
    "# Drop unneeded columns\n",
    "df2.drop(['Date', 'Time', 'rain_amount', 'rain_desc'], axis=1, inplace=True)\n",
    "\n",
    " # Define additional features\n",
    "df2['Date Time'] = pd.to_datetime(df2['DateAndTime'], format='%d.%m.%Y %H.%M.%S')\n",
    "df2['hour'] = df2['Date Time'].dt.hour\n",
    "df2['day_of_week'] = df2['Date Time'].dt.dayofweek\n",
    "df2['month'] = df2['Date Time'].dt.month\n",
    "df2['year'] = df2['Date Time'].dt.year\n",
    "df2.drop(['DateAndTime', 'Day', 'is_weekend'], axis=1, inplace=True)\n",
    "df2['is_weekend'] = df2['day_of_week'].apply(lambda x: 1 if x in [5, 6] else 0)\n",
    "model_features = ['hour', 'day_of_week', 'is_weekend', 'month', 'year', 'rain_class', 'Entry']\n",
    "df_model = df2[model_features]\n",
    "\n",
    "# Normalize all features except 'Entry'\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_model[df_model.columns[:-1]] = scaler.fit_transform(df_model[df_model.columns[:-1]])\n",
    "\n",
    "# Save the scaler for the features\n",
    "joblib.dump(scaler, 'model/scaler_features.pkl')\n",
    "\n",
    "# Normalize the 'Entry' column separately\n",
    "scaler_entry = MinMaxScaler(feature_range=(0, 1))\n",
    "df_model['Entry'] = scaler_entry.fit_transform(df_model[['Entry']])\n",
    "\n",
    "# Save the scaler for the 'Entry' column\n",
    "joblib.dump(scaler_entry, 'model/scaler_entry.pkl')\n",
    "\n",
    "#\n",
    "X, y = df_to_X_y(df_model)\n",
    "\n",
    "# First split: Train and remaining (validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Second split: Split the remaining into validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "lstm_forecast = lstm_model(df2, X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LSTM\n",
       "0        0.0\n",
       "1     2270.0\n",
       "2     4295.0\n",
       "3     5360.0\n",
       "4     4528.0\n",
       "...      ...\n",
       "1455  1611.0\n",
       "1456  1239.0\n",
       "1457     0.0\n",
       "1458     0.0\n",
       "1459     0.0\n",
       "\n",
       "[1460 rows x 1 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_forecast = pd.DataFrame(lstm_forecast, columns=['LSTM'])\n",
    "lstm_forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>All Saints' Day</th>\n",
       "      <th>All Saints' Day_lower</th>\n",
       "      <th>All Saints' Day_upper</th>\n",
       "      <th>Black Saturday</th>\n",
       "      <th>...</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-08 04:00:00</td>\n",
       "      <td>1502.743646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>518.323348</td>\n",
       "      <td>1502.743646</td>\n",
       "      <td>1502.743646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083363</td>\n",
       "      <td>0.083363</td>\n",
       "      <td>0.083363</td>\n",
       "      <td>-0.038610</td>\n",
       "      <td>-0.038610</td>\n",
       "      <td>-0.038610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-08 05:00:00</td>\n",
       "      <td>1502.802962</td>\n",
       "      <td>2148.303691</td>\n",
       "      <td>3321.362160</td>\n",
       "      <td>1502.802962</td>\n",
       "      <td>1502.802962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079941</td>\n",
       "      <td>0.079941</td>\n",
       "      <td>0.079941</td>\n",
       "      <td>-0.038131</td>\n",
       "      <td>-0.038131</td>\n",
       "      <td>-0.038131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-08 06:00:00</td>\n",
       "      <td>1502.862279</td>\n",
       "      <td>3851.918152</td>\n",
       "      <td>5067.337599</td>\n",
       "      <td>1502.862279</td>\n",
       "      <td>1502.862279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076329</td>\n",
       "      <td>0.076329</td>\n",
       "      <td>0.076329</td>\n",
       "      <td>-0.037649</td>\n",
       "      <td>-0.037649</td>\n",
       "      <td>-0.037649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-08 07:00:00</td>\n",
       "      <td>1502.921595</td>\n",
       "      <td>4200.353122</td>\n",
       "      <td>5403.175454</td>\n",
       "      <td>1502.921595</td>\n",
       "      <td>1502.921595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>-0.037165</td>\n",
       "      <td>-0.037165</td>\n",
       "      <td>-0.037165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-08 08:00:00</td>\n",
       "      <td>1502.980911</td>\n",
       "      <td>3709.242341</td>\n",
       "      <td>4886.002137</td>\n",
       "      <td>1502.980911</td>\n",
       "      <td>1502.980911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068760</td>\n",
       "      <td>0.068760</td>\n",
       "      <td>0.068760</td>\n",
       "      <td>-0.036677</td>\n",
       "      <td>-0.036677</td>\n",
       "      <td>-0.036677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>1710.054302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5564.217238</td>\n",
       "      <td>-757.368822</td>\n",
       "      <td>4067.479155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080293</td>\n",
       "      <td>-0.080293</td>\n",
       "      <td>-0.080293</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>1710.113618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4230.921401</td>\n",
       "      <td>-758.527170</td>\n",
       "      <td>4068.536920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071339</td>\n",
       "      <td>-0.071339</td>\n",
       "      <td>-0.071339</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>1710.172935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1780.707530</td>\n",
       "      <td>-759.685518</td>\n",
       "      <td>4069.594685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>1710.232251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>565.771905</td>\n",
       "      <td>-760.843866</td>\n",
       "      <td>4070.652450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052290</td>\n",
       "      <td>-0.052290</td>\n",
       "      <td>-0.052290</td>\n",
       "      <td>-0.008801</td>\n",
       "      <td>-0.008801</td>\n",
       "      <td>-0.008801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>1710.291567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>597.926875</td>\n",
       "      <td>-762.002214</td>\n",
       "      <td>4071.710215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>-0.008326</td>\n",
       "      <td>-0.008326</td>\n",
       "      <td>-0.008326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2920 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ds        trend   yhat_lower   yhat_upper  trend_lower  \\\n",
       "0    2023-08-08 04:00:00  1502.743646     0.000000   518.323348  1502.743646   \n",
       "1    2023-08-08 05:00:00  1502.802962  2148.303691  3321.362160  1502.802962   \n",
       "2    2023-08-08 06:00:00  1502.862279  3851.918152  5067.337599  1502.862279   \n",
       "3    2023-08-08 07:00:00  1502.921595  4200.353122  5403.175454  1502.921595   \n",
       "4    2023-08-08 08:00:00  1502.980911  3709.242341  4886.002137  1502.980911   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "2915 2023-12-31 19:00:00  1710.054302     0.000000  5564.217238  -757.368822   \n",
       "2916 2023-12-31 20:00:00  1710.113618     0.000000  4230.921401  -758.527170   \n",
       "2917 2023-12-31 21:00:00  1710.172935     0.000000  1780.707530  -759.685518   \n",
       "2918 2023-12-31 22:00:00  1710.232251     0.000000   565.771905  -760.843866   \n",
       "2919 2023-12-31 23:00:00  1710.291567     0.000000   597.926875  -762.002214   \n",
       "\n",
       "      trend_upper  All Saints' Day  All Saints' Day_lower  \\\n",
       "0     1502.743646              0.0                    0.0   \n",
       "1     1502.802962              0.0                    0.0   \n",
       "2     1502.862279              0.0                    0.0   \n",
       "3     1502.921595              0.0                    0.0   \n",
       "4     1502.980911              0.0                    0.0   \n",
       "...           ...              ...                    ...   \n",
       "2915  4067.479155              0.0                    0.0   \n",
       "2916  4068.536920              0.0                    0.0   \n",
       "2917  4069.594685              0.0                    0.0   \n",
       "2918  4070.652450              0.0                    0.0   \n",
       "2919  4071.710215              0.0                    0.0   \n",
       "\n",
       "      All Saints' Day_upper  Black Saturday  ...    weekly  weekly_lower  \\\n",
       "0                       0.0             0.0  ...  0.083363      0.083363   \n",
       "1                       0.0             0.0  ...  0.079941      0.079941   \n",
       "2                       0.0             0.0  ...  0.076329      0.076329   \n",
       "3                       0.0             0.0  ...  0.072584      0.072584   \n",
       "4                       0.0             0.0  ...  0.068760      0.068760   \n",
       "...                     ...             ...  ...       ...           ...   \n",
       "2915                    0.0             0.0  ... -0.080293     -0.080293   \n",
       "2916                    0.0             0.0  ... -0.071339     -0.071339   \n",
       "2917                    0.0             0.0  ... -0.061977     -0.061977   \n",
       "2918                    0.0             0.0  ... -0.052290     -0.052290   \n",
       "2919                    0.0             0.0  ... -0.042360     -0.042360   \n",
       "\n",
       "      weekly_upper    yearly  yearly_lower  yearly_upper  additive_terms  \\\n",
       "0         0.083363 -0.038610     -0.038610     -0.038610             0.0   \n",
       "1         0.079941 -0.038131     -0.038131     -0.038131             0.0   \n",
       "2         0.076329 -0.037649     -0.037649     -0.037649             0.0   \n",
       "3         0.072584 -0.037165     -0.037165     -0.037165             0.0   \n",
       "4         0.068760 -0.036677     -0.036677     -0.036677             0.0   \n",
       "...            ...       ...           ...           ...             ...   \n",
       "2915     -0.080293 -0.010234     -0.010234     -0.010234             0.0   \n",
       "2916     -0.071339 -0.009755     -0.009755     -0.009755             0.0   \n",
       "2917     -0.061977 -0.009277     -0.009277     -0.009277             0.0   \n",
       "2918     -0.052290 -0.008801     -0.008801     -0.008801             0.0   \n",
       "2919     -0.042360 -0.008326     -0.008326     -0.008326             0.0   \n",
       "\n",
       "      additive_terms_lower  additive_terms_upper    yhat  \n",
       "0                      0.0                   0.0     0.0  \n",
       "1                      0.0                   0.0  2736.0  \n",
       "2                      0.0                   0.0  4448.0  \n",
       "3                      0.0                   0.0  4818.0  \n",
       "4                      0.0                   0.0  4298.0  \n",
       "...                    ...                   ...     ...  \n",
       "2915                   0.0                   0.0  2322.0  \n",
       "2916                   0.0                   0.0  1778.0  \n",
       "2917                   0.0                   0.0   688.0  \n",
       "2918                   0.0                   0.0     0.0  \n",
       "2919                   0.0                   0.0     0.0  \n",
       "\n",
       "[2920 rows x 94 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ds        trend   yhat_lower   yhat_upper  trend_lower  \\\n",
      "0    2023-10-20 04:00:00  1606.665897     0.000000   286.650956   800.544107   \n",
      "1    2023-10-20 05:00:00  1606.725214  1206.263154  4030.704537   799.662457   \n",
      "2    2023-10-20 06:00:00  1606.784530  2126.891225  6669.758819   798.780808   \n",
      "3    2023-10-20 07:00:00  1606.843846  2346.169432  7325.307636   797.899159   \n",
      "4    2023-10-20 08:00:00  1606.903163  2107.075463  6617.419672   797.017510   \n",
      "...                  ...          ...          ...          ...          ...   \n",
      "1455 2023-12-31 19:00:00  1710.054302     0.000000  5564.217238  -757.368822   \n",
      "1456 2023-12-31 20:00:00  1710.113618     0.000000  4230.921401  -758.527170   \n",
      "1457 2023-12-31 21:00:00  1710.172935     0.000000  1780.707530  -759.685518   \n",
      "1458 2023-12-31 22:00:00  1710.232251     0.000000   565.771905  -760.843866   \n",
      "1459 2023-12-31 23:00:00  1710.291567     0.000000   597.926875  -762.002214   \n",
      "\n",
      "      trend_upper  All Saints' Day  All Saints' Day_lower  \\\n",
      "0     2396.210532              0.0                    0.0   \n",
      "1     2397.141346              0.0                    0.0   \n",
      "2     2398.072159              0.0                    0.0   \n",
      "3     2399.002972              0.0                    0.0   \n",
      "4     2399.933786              0.0                    0.0   \n",
      "...           ...              ...                    ...   \n",
      "1455  4067.479155              0.0                    0.0   \n",
      "1456  4068.536920              0.0                    0.0   \n",
      "1457  4069.594685              0.0                    0.0   \n",
      "1458  4070.652450              0.0                    0.0   \n",
      "1459  4071.710215              0.0                    0.0   \n",
      "\n",
      "      All Saints' Day_upper  Black Saturday  ...    weekly  weekly_lower  \\\n",
      "0                       0.0             0.0  ... -0.026443     -0.026443   \n",
      "1                       0.0             0.0  ... -0.021457     -0.021457   \n",
      "2                       0.0             0.0  ... -0.016175     -0.016175   \n",
      "3                       0.0             0.0  ... -0.010652     -0.010652   \n",
      "4                       0.0             0.0  ... -0.004951     -0.004951   \n",
      "...                     ...             ...  ...       ...           ...   \n",
      "1455                    0.0             0.0  ... -0.080293     -0.080293   \n",
      "1456                    0.0             0.0  ... -0.071339     -0.071339   \n",
      "1457                    0.0             0.0  ... -0.061977     -0.061977   \n",
      "1458                    0.0             0.0  ... -0.052290     -0.052290   \n",
      "1459                    0.0             0.0  ... -0.042360     -0.042360   \n",
      "\n",
      "      weekly_upper    yearly  yearly_lower  yearly_upper  additive_terms  \\\n",
      "0        -0.026443 -0.064640     -0.064640     -0.064640             0.0   \n",
      "1        -0.021457 -0.065450     -0.065450     -0.065450             0.0   \n",
      "2        -0.016175 -0.066255     -0.066255     -0.066255             0.0   \n",
      "3        -0.010652 -0.067057     -0.067057     -0.067057             0.0   \n",
      "4        -0.004951 -0.067854     -0.067854     -0.067854             0.0   \n",
      "...            ...       ...           ...           ...             ...   \n",
      "1455     -0.080293 -0.010234     -0.010234     -0.010234             0.0   \n",
      "1456     -0.071339 -0.009755     -0.009755     -0.009755             0.0   \n",
      "1457     -0.061977 -0.009277     -0.009277     -0.009277             0.0   \n",
      "1458     -0.052290 -0.008801     -0.008801     -0.008801             0.0   \n",
      "1459     -0.042360 -0.008326     -0.008326     -0.008326             0.0   \n",
      "\n",
      "      additive_terms_lower  additive_terms_upper    yhat  \n",
      "0                      0.0                   0.0     0.0  \n",
      "1                      0.0                   0.0  2664.0  \n",
      "2                      0.0                   0.0  4507.0  \n",
      "3                      0.0                   0.0  4916.0  \n",
      "4                      0.0                   0.0  4372.0  \n",
      "...                    ...                   ...     ...  \n",
      "1455                   0.0                   0.0  2322.0  \n",
      "1456                   0.0                   0.0  1778.0  \n",
      "1457                   0.0                   0.0   688.0  \n",
      "1458                   0.0                   0.0     0.0  \n",
      "1459                   0.0                   0.0     0.0  \n",
      "\n",
      "[1460 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows\n",
    "num_rows = len(test_forecast)\n",
    "\n",
    "# Calculate the midpoint\n",
    "midpoint = num_rows // 2\n",
    "\n",
    "# Take the latter half\n",
    "prophet_forecast = test_forecast[midpoint:]\n",
    "hybrid_actual = test[midpoint:]\n",
    "\n",
    "# Reset the index of the DataFrame and drop the old index\n",
    "prophet_forecast.reset_index(drop=True, inplace=True)\n",
    "hybrid_actual.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(prophet_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ds  prophet    lstm     y\n",
      "0    2023-10-20 04:00:00      0.0     0.0     0\n",
      "1    2023-10-20 05:00:00   2664.0  2270.0  2894\n",
      "2    2023-10-20 06:00:00   4507.0  4295.0  4339\n",
      "3    2023-10-20 07:00:00   4916.0  5360.0  5548\n",
      "4    2023-10-20 08:00:00   4372.0  4528.0  4502\n",
      "...                  ...      ...     ...   ...\n",
      "1455 2023-12-31 19:00:00   2322.0  1611.0  1681\n",
      "1456 2023-12-31 20:00:00   1778.0  1239.0   297\n",
      "1457 2023-12-31 21:00:00    688.0     0.0     0\n",
      "1458 2023-12-31 22:00:00      0.0     0.0     0\n",
      "1459 2023-12-31 23:00:00      0.0     0.0     0\n",
      "\n",
      "[1460 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "hybrid_forecast = prophet_forecast[['ds', 'yhat']].rename(columns={'yhat': 'prophet'})\n",
    "hybrid_forecast['lstm'] = lstm_forecast['LSTM']\n",
    "hybrid_forecast['y'] = hybrid_actual['y']\n",
    "print(hybrid_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 94169.6863\n",
      "RMSE: 306.8708\n",
      "MAE: 185.8411\n",
      "R²: 0.9487\n"
     ]
    }
   ],
   "source": [
    "# Define weights\n",
    "weight_prophet = 0.1\n",
    "weight_lstm = 0.9\n",
    "\n",
    "# Calculate the hybrid forecast\n",
    "hybrid_forecast['yhat'] = (\n",
    "    weight_prophet * hybrid_forecast['prophet'] + \n",
    "    weight_lstm * hybrid_forecast['lstm']\n",
    ")\n",
    "\n",
    "actual = hybrid_forecast['y']\n",
    "forecast = hybrid_forecast['hybrid_forecast']\n",
    "\n",
    "#Evaluate hybrid forecast\n",
    "mse, rmse, mae, r2 = evaluate_model(hybrid_forecast, hybrid_forecast)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
